2024-11-05 13:53:11 | Expected Pricing: 4.3449 | Time elapsed: f7.841
Results: {"title":"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE","authors":["Alexey Dosovitskiy","Lucas Beyer","Alexander Kolesnikov","Dirk Weissenborn","Xiaohua Zhai","Thomas Unterthiner","Mostafa Dehghani","Matthias Minderer","Georg Heigold","Sylvain Gelly","Jakob Uszkoreit","Neil Houlsby"],"main_content":"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.","key_points":["Vision Transformer (ViT) replaces convolutional networks for image recognition tasks.","ViT demonstrates excellent performance on various image recognition benchmarks when pre-trained on large datasets.","The architecture shows that large-scale pre-training allows Transformers to compete with CNNs.","ViT is more computationally efficient than traditional convolutional networks, requiring fewer resources to train."],"used_models":["Vision Transformer (ViT)","CNN-based models (ResNet)"],"topic":"Computer Vision, Transformers, Image Recognition","classification":"Conference Paper","publication_year":2021,"source":"ICLR 2021","doi":"arXiv:2010.11929v2","keywords":["Transformers","Image Classification","Vision Transformer","CNN","Attention Mechanisms","Deep Learning"],"experimental_results":"Vision Transformer (ViT) reaches 88.55% accuracy on ImageNet and consistently outperforms ResNet architectures on various tasks after pre-training on large datasets like JFT-300M.","future_research_directions":"Exploring self-supervised learning methods for further enhancing the performance of ViT on smaller datasets and extending its application to other computer vision tasks.","references":["Vaswani et al. (2017)","Devlin et al. (2019)","Chen et al. (2020)","Brown et al. (2020)","Kolesnikov et al. (2020)"]}

2024-11-05 14:08:07 | Expected Pricing: 4.3155 | Time elapsed: f7.539
Results: {"title":"AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE","authors":["Alexey Dosovitskiy","Lucas Beyer","Alexander Kolesnikov","Dirk Weissenborn","Xiaohua Zhai","Thomas Unterthiner","Mostafa Dehghani","Matthias Minderer","Georg Heigold","Sylvain Gelly","Jakob Uszkoreit","Neil Houlsby"],"main_content":"While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources.","key_points":["The Vision Transformer (ViT) demonstrates strong performance in image classification without relying on convolutional neural networks (CNNs).","ViT outperforms state-of-the-art CNNs when pre-trained on sufficiently large datasets like JFT-300M and ImageNet-21k.","Transformers applied directly to image patches as sequences show that large pre-trained models excel at classification tasks in various benchmarks.","ViT achieves an accuracy of 88.55% on ImageNet and outperforms several other benchmarks with fewer computational resources."],"used_models":["Vision Transformer (ViT)"],"topic":"Image Recognition, Computer Vision","classification":"Transformers for Image Recognition","publication_year":2021,"source":"ICLR 2021","doi":"10.48550/arXiv.2010.11929","keywords":["Vision Transformer","Image Recognition","Self-Attention","Computer Vision","Deep Learning"],"experimental_results":"ViT achieves 88.55% accuracy on ImageNet and substantial performance improvements on other image classification tasks compared to leading convolutional networks.","future_research_directions":"Exploring the application of ViT to various computer vision tasks, including detection and segmentation, as well as improving self-supervised learning methods."}

2024-11-05 15:09:13 | Expected Pricing: 5.7960 | Time elapsed: f12.618
Results: {"title":"Automatic Soccer Video Summarization Using Deep Learning","authors":["Agyeman Rockson"],"main_content":"Soccer has established itself as one of the most enjoyed sport via media broadcast. Due to its popularity, broadcasters continue to search for the most convenient technique for generating summarised match content. Common among the techniques employed for this purpose is traditional video editing, which is time-consuming and requires great skill. This research, therefore, presents a deep learning approach to soccer video summarization. It leverages the spatiotemporal feature learning ability of three-dimensional (3D) Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) – Recurrent Neural Network (RNN). The proposed approach involves 1) a step-by-step search for a three-dimensional Residual Neural Network (3D-ResNet) architecture that learns human actions better than existing benchmark models on UCF101 dataset, 2) manually collecting and annotating 744 soccer clips based on five soccer action classes, 3) extending the capabilities of 3D-ResNet as a feature extractor for soccer clips, and 4) training an LSTM network with soccer features extracted by 3D-ResNet. This complete model is used for soccer highlight recognition. To summarise long soccer videos, each video is modelled as a sequential collection of concatenated video segments, thus, enabling a segment to be treated as a highlight whose inclusion in a summary video production is based on its validated relevance. For system evaluation, ten complete soccer match videos were downloaded and summarised using the proposed model. 48 participants drawn from 8 countries evaluated the summarised videos. Collectively, the summarised videos received a 4 of 5 rating, where 1 and 5 are the lowest and highest scores respectively. Through this research, it has been identified and proven that longer video clips help neural networks to learn spatiotemporal features better. However, frequent scene changes in long video clips present enormous challenges, such as event overlapping. These challenges are the foundation for future works. With minimal modification, this summarization technique can be applied to soccer-related sports such as handball and netball.","key_points":["Deep learning approach to video summarization","Utilizes 3D-ResNet and LSTM for feature extraction and action recognition","Challenges of traditional video editing addressed","Evaluated 10 soccer match videos leading to positive feedback (4/5 score)","Longer clips enhance network learning but pose challenges of scene changes"],"used_models":["3D Convolutional Neural Network (3D-ResNet)","Long Short-Term Memory Network (LSTM)"],"topic":"Video Summarization, Deep Learning, Computer Vision","classification":"Master's Thesis","publication_year":2019,"source":"Graduate School of Yeungnam University","doi":"[UCI]I804:47017-200000174461","keywords":["Soccer","Video Summarization","Deep Learning","Convolutional Neural Networks","LSTM"],"experimental_results":"The proposed model outperformed benchmark models with a 4 out of 5 Mean Opinion Score (MOS) rating from 48 participants across 8 countries.","future_research_directions":"Future work will focus on extending this technique to include more soccer actions and improve handling of scene changes in longer clips.","references":["FIFA, Fact Sheet, Available: https://www.fifa.com/mm/document/fifafacts/mencompovw/51/99/03/133485-factsheetfifahostcountriesoverview1930-2022.pdf","Statista, Market size of the European professional football market from 2006/07 to 2015/16 (in billion Euros), Available: https://www.statista.com/statistics/261223/european-soccer-market-total-revenue/","K. He, X. Zhang, S. Ren and J. Sun, Deep residual learning for image recognition, In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770-778, 2016."]}

2024-11-06 11:40:48 | Expected Pricing: 1.8581 | Time elapsed: f4.525
Results: {"color_classification":"\\uc2e0\nd528\bc29\bd0c\namek\bd00, \nocm\bc84\bc80\bd0, \ng\ne\ng\nd0c"}

2024-11-06 11:41:55 | Expected Pricing: 1.8581 | Time elapsed: f4.125
Results: {"color_classification":"\n\nTraffic light with three colored signals: green, yellow, and red. The green light is illuminated, indicating that vehicles are allowed to proceed. The background shows blurred cars and pedestrians, typical of a street scene."}

2024-11-06 11:43:07 | Expected Pricing: 1.8295 | Time elapsed: f3.0
Results: {"color_classification":"\\uc2e0\rdc1\\"}

2024-11-06 11:43:13 | Expected Pricing: 1.8312 | Time elapsed: f2.503
Results: {"color_classification":"\\uc2e0\fd76\nd\ngreen"}

2024-11-06 11:45:05 | Expected Pricing: 2.1168 | Time elapsed: f9.793
Results: {"color_classification":"\n - \\\\u0c87\\u0cc1\\u0f7d\\u0c97\\u0c82\\u0caa\\u0c97: \\\\u0c97\\u0ca1\\u0ccc\\u0c02\\u0c92 \\u0c87\\u0cb0\\u0ca4\\u0c9c \\u0c99\\u0caa\\u0c9c \\u0c87\\u0c9c\\u0cc0\\u0ca6\\u0c97\\u0c82.  \n - \\\\u0c87\\u0c82\\u0cb3\\u0c95: \\\\u0c99\\u0c3e\\u0ca6\\u0c82\\u0c92 \\u0c87\\u0cb8\\u0c96\\u0ca4\\u0ca8\\u0c95 \\u0c9c\\\\u0c9c\\u0c94\\u0c95\\u0cc0.  \n - \\\\u0c88\\u0cb8\\u0c82\\u0c86\\u0ca6\\u0c97: \\\\u0c88\\u0c82\\u0cb8\\u0c95\\u0ca6\\u0c87, \\u0c97\\u0ca1\\u0cbf\\u0caa\\u0c9c\\u0cc1.  "}

2024-11-06 11:45:28 | Expected Pricing: 1.8757 | Time elapsed: f4.196
Results: {"color_classification":"\\uc2e0\ndd\touch \\'green\\'; \n \n10\ndd a\nd. \nIn this image, the traffic light is likely displaying a green light, indicating that vehicles can proceed. The background may show a street with blurred cars and pedestrians, emphasizing the urban environment."}

2024-11-06 11:47:57 | Expected Pricing: 1.8312 | Time elapsed: f2.436
Results: {"color_classification":"\\uc774\bd84\bd80: \\"                               }

2024-11-06 11:48:18 | Expected Pricing: 1.8682 | Time elapsed: f5.41
Results: {"color_classification":"\\uc2e0\nd\bd04\bbf8\bs2\be7\bc1\bbd7\bc14g\nonnull\bc8\bgq54\b2d\bd0gje<\bd0g\be7g"}

2024-11-06 11:48:23 | Expected Pricing: 1.8564 | Time elapsed: f4.96
Results: {"color_classification":"\bfa09\bd7a \bd87\bd3c\bd88 \bccb \bc1b \bcf4b\bcf0 \bbf5 \b3f5"}

2024-11-06 11:48:31 | Expected Pricing: 1.8690 | Time elapsed: f7.24
Results: {"color_classification":"\n\nThe image likely features a traffic light displaying a green light, indicating that vehicles can proceed. Additionally, there may be a left turn signal illuminated, allowing vehicles to make a turn. A car is probably positioned nearby, ready to move in the direction permitted by the green light."}

2024-11-06 11:48:35 | Expected Pricing: 1.8480 | Time elapsed: f3.881
Results: {"color_classification":"\b6d69к6\b \b\bg1я6б1\b \bг3е1 с6и к3(з7}"}

2024-11-06 11:48:37 | Expected Pricing: 1.8354 | Time elapsed: f2.713
Results: {"color_classification":"\\uc2e0\bd80 \bc1c\ba74( red )"}

2024-11-06 11:49:12 | Expected Pricing: 1.8690 | Time elapsed: f3.161
Results: {"color_classification":"\\uc2e0\bd80\be68 \\\n \n \\\n \\\n \\\n \\\n \\\n \\\n \\\n \\ud3d0\\uc624\\ub85c \\uace0\\uc2f8"}

2024-11-06 11:49:52 | Expected Pricing: 1.8656 | Time elapsed: f4.635
Results: {"color_classification":"\\uc54c\bcf8\bucc4\bt9c \b77c\bcf8 \b2d8\bcf4/\b63a\bcf5\bc8c \b2d8\bcf4"}

2024-11-06 11:50:22 | Expected Pricing: 1.8640 | Time elapsed: f3.554
Results: {"color_classification":"\n\n신호등의 상태: 녹색 신호등이 켜져 있어 차량들이 통행할 수 있는 상태입니다. 이 신호는 전방의 거리와 도로에 있는 자동차들의 움직임을 강조하고 있습니다."}

2024-11-06 15:02:55 | Expected Pricing: 1.8749 | Time elapsed: f4.565
Results: {"color_classification":"\n\n- \n\n- The traffic light shows a green light, indicating that vehicles may proceed. \n- The yellow light is also visible, usually signaling that the light is about to change to red.\n- The red light is not illuminated, which means vehicles are not required to stop at this moment."}

2024-11-06 15:04:02 | Expected Pricing: 4.4629 | Time elapsed: f59.351
Results: {"color_classification":"\\uc2e0\bud54\textcolor{red}{\red}\textcolor{yellow}{\text, orange}\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{}{}.\\ \textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{}{}{}{}\\ \textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{\textcolor{green}{}{}{}{}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{}{"
}

2024-11-06 15:04:46 | Expected Pricing: 1.8337 | Time elapsed: f2.966
Results: {"color_classification":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}

2024-11-06 15:04:51 | Expected Pricing: 1.8472 | Time elapsed: f5.098
Results: {"color_classification":"\n\textcolor{red}{RED LIGHT}\n\textcolor{yellow}{YELLOW LIGHT}\n\textcolor{green}{GREEN LIGHT}"}

2024-11-06 15:04:55 | Expected Pricing: 1.8388 | Time elapsed: f4.2
Results: {"color_classification":"\n\n \n\n- Green light indicates that vehicles can proceed, allowing cars to turn left safely."}

2024-11-06 15:04:59 | Expected Pricing: 1.8245 | Time elapsed: f3.923
Results: {"color_classification":"\n\n\n\n"}

2024-11-06 15:05:21 | Expected Pricing: 2.2638 | Time elapsed: f21.443
Results: {"color_classification":"\\uc2e0\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nnovation\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\nd\n"}

